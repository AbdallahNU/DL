{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emojify 😃"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.layers as tfl\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_glove_vecs(glove_file):\n",
    "    with open(glove_file, 'r') as f:\n",
    "        words = set()\n",
    "        word_to_vec_map = {}\n",
    "        for line in f:\n",
    "            line = line.strip().split()\n",
    "            curr_word = line[0]\n",
    "            words.add(curr_word)\n",
    "            word_to_vec_map[curr_word] = np.array(line[1:], dtype=np.float64)\n",
    "        \n",
    "        i = 1\n",
    "        words_to_index = {}\n",
    "        index_to_words = {}\n",
    "        for w in sorted(words):\n",
    "            words_to_index[w] = i\n",
    "            index_to_words[i] = w\n",
    "            i = i + 1\n",
    "    return words_to_index, index_to_words, word_to_vec_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentences_to_indices(X, word_to_index, max_len):\n",
    "    \"\"\"\n",
    "    Converts an array of sentences (strings) into an array of indices corresponding to words in the sentences.\n",
    "    \n",
    "    Inputs:\n",
    "        X -- array of sentences (strings), of shape (m, 1)\n",
    "        word_to_index -- a dictionary containing the each word mapped to its index\n",
    "        max_len -- maximum number of words in a sentence. You can assume every sentence in X is no longer than this. \n",
    "    \n",
    "    Returns:\n",
    "        X_indices -- array of indices corresponding to words in the sentences from X, of shape (m, max_len)\n",
    "    \"\"\"\n",
    "    \n",
    "    # get number of examples\n",
    "    m = X.shape[0]\n",
    "    \n",
    "    # initialize indices matrix with zeros\n",
    "    X_indices = np.zeros((m, max_len))\n",
    "    \n",
    "    # loop over training examples\n",
    "    for i in range(m):\n",
    "        \n",
    "        # get list sentence words and convert to lower\n",
    "        sentence_words = X[i].lower().split()\n",
    "        \n",
    "        j = 0\n",
    "        \n",
    "        # loop over sentence words\n",
    "        for word in sentence_words:\n",
    "            \n",
    "            # if word exists in word_to_index dectionary\n",
    "            if word in word_to_index:\n",
    "                # Set the (i,j)th entry of X_indices to the index of the correct word.\n",
    "                X_indices[i, j] = word_to_index[word]\n",
    "                \n",
    "                # increament j\n",
    "                j+=1\n",
    "        \n",
    "    return X_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrained_embedding_layer(word_to_vec_map, word_to_index):\n",
    "    \"\"\"\n",
    "    Creates a Keras Embedding() layer and loads in pre-trained GloVe 50-dimensional vectors.\n",
    "    \n",
    "    Inputs:\n",
    "        word_to_vec_map -- dictionary mapping words to their GloVe vector representation.\n",
    "        word_to_index -- dictionary mapping from words to their indices in the vocabulary (400,001 words)\n",
    "\n",
    "    Returns:\n",
    "        embedding_layer -- pretrained layer Keras instance\n",
    "    \"\"\"\n",
    "    \n",
    "    # adding 1 to fit Keras embedding\n",
    "    vocab_size = len(word_to_index) + 1              \n",
    "    any_word = list(word_to_vec_map.keys())[0]\n",
    "    \n",
    "    # define dimensionality of the GloVe word vectors (= 50)\n",
    "    emb_dim = word_to_vec_map[any_word].shape[0]    \n",
    "      \n",
    "\n",
    "    # Initialize the embedding matrix as a numpy array of zeros.\n",
    "    emb_matrix = np.zeros((vocab_size, emb_dim))\n",
    "    \n",
    "    # Set each row \"idx\" of the embedding matrix to be \n",
    "    # the word vector representation of the idx'th word of the vocabulary\n",
    "    for word, idx in word_to_index.items():\n",
    "        emb_matrix[idx, :] = word_to_vec_map[word]\n",
    "\n",
    "    # Define Keras embedding layer with the correct input and output sizes\n",
    "    embedding_layer = tfl.Embedding(vocab_size, emb_dim)\n",
    "\n",
    "    # Build the embedding layer\n",
    "    embedding_layer.build((None,))\n",
    "    \n",
    "    # Set the weights of the embedding layer to the embedding matrix. Your layer is now pretrained.\n",
    "    embedding_layer.set_weights([emb_matrix])\n",
    "    \n",
    "    return embedding_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_to_emoji(label):\n",
    "    \"\"\"\n",
    "    Converts a label (int or string) into the corresponding emoji code (string) ready to be printed\n",
    "    \"\"\"\n",
    "    return emoji.emojize(emoji_dictionary[str(label)], use_aliases=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Emojify(input_shape, word_to_vec_map, word_to_index):\n",
    "    \"\"\"\n",
    "    Function creating the Emojify model's graph.\n",
    "    \n",
    "    Inputs:\n",
    "        input_shape -- shape of the input, usually (max_len,)\n",
    "        word_to_vec_map -- dictionary mapping every word in a vocabulary into its 50-dimensional vector representation\n",
    "        word_to_index -- dictionary mapping from words to their indices in the vocabulary (400,001 words)\n",
    "\n",
    "    Returns:\n",
    "        model -- a model instance in Keras\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define sentence_indices as the input of the graph.\n",
    "    sentence_indices = tfl.Input(shape=input_shape, dtype='int32')\n",
    "    \n",
    "    # Create the embedding layer pretrained with GloVe Vectors\n",
    "    embedding_layer = pretrained_embedding_layer(word_to_vec_map, word_to_index)\n",
    "    \n",
    "    # Propagate sentence_indices through your embedding layer\n",
    "    embeddings = embedding_layer(sentence_indices) \n",
    "    \n",
    "    # Propagate the embeddings through an LSTM layer with 128-dimensional hidden state\n",
    "    X = tfl.LSTM(128, return_sequences=True)(embeddings)\n",
    "    \n",
    "    # Add dropout with a probability of 0.5\n",
    "    X = tfl.Dropout(0.5)(X) \n",
    "    \n",
    "    # Propagate X trough another LSTM layer with 128-dimensional hidden state\n",
    "    X = tfl.LSTM(128)(X)\n",
    "    \n",
    "    # Add dropout with a probability of 0.5\n",
    "    X = tfl.Dropout(0.5)(X) \n",
    "    \n",
    "    # Propagate X through a Dense layer with 5 units\n",
    "    X = tfl.Dense(5)(X)\n",
    "    \n",
    "    # Add a softmax activation\n",
    "    X = tfl.Activation('softmax')(X)\n",
    "    \n",
    "    # Create the model\n",
    "    model = keras.Model(inputs=sentence_indices, outputs=X)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index, index_to_word, word_to_vec_map = read_glove_vecs('/home/abdalla/Datasets/emoji/glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/home/abdalla/Datasets/emoji/train_emoji.csv').iloc[:,:2].values\n",
    "test = pd.read_csv('/home/abdalla/Datasets/emoji/test_emoji.csv').iloc[:,:2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train[:,0], np.asarray(train[:,1], dtype=int)\n",
    "X_test, y_test = test[:,0], np.asarray(test[:,1], dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxLen = len(max(X_train, key=len).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_indices = sentences_to_indices(X_train, word_to_index, maxLen)\n",
    "y_train_oh = np.eye(5)[y_train.reshape(-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_indices = sentences_to_indices(X_test, word_to_index, max_len = maxLen)\n",
    "y_test_oh = np.eye(5)[y_test.reshape(-1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 10)]              0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 10, 50)            20000050  \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 10, 128)           91648     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 10, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 645       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 20,223,927\n",
      "Trainable params: 20,223,927\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Emojify((maxLen,), word_to_vec_map, word_to_index)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "5/5 [==============================] - 4s 420ms/step - loss: 1.6016 - accuracy: 0.2272 - val_loss: 1.5272 - val_accuracy: 0.3091\n",
      "Epoch 2/30\n",
      "5/5 [==============================] - 1s 301ms/step - loss: 1.5022 - accuracy: 0.3493 - val_loss: 1.4881 - val_accuracy: 0.3273\n",
      "Epoch 3/30\n",
      "5/5 [==============================] - 1s 301ms/step - loss: 1.4494 - accuracy: 0.3364 - val_loss: 1.4610 - val_accuracy: 0.3273\n",
      "Epoch 4/30\n",
      "5/5 [==============================] - 2s 305ms/step - loss: 1.3280 - accuracy: 0.5168 - val_loss: 1.4083 - val_accuracy: 0.4364\n",
      "Epoch 5/30\n",
      "5/5 [==============================] - 2s 303ms/step - loss: 1.1994 - accuracy: 0.6244 - val_loss: 1.3617 - val_accuracy: 0.4364\n",
      "Epoch 6/30\n",
      "5/5 [==============================] - 2s 303ms/step - loss: 1.0210 - accuracy: 0.7396 - val_loss: 1.2863 - val_accuracy: 0.4364\n",
      "Epoch 7/30\n",
      "5/5 [==============================] - 2s 303ms/step - loss: 0.9569 - accuracy: 0.6165 - val_loss: 1.2484 - val_accuracy: 0.4909\n",
      "Epoch 8/30\n",
      "5/5 [==============================] - 2s 304ms/step - loss: 0.7657 - accuracy: 0.7170 - val_loss: 1.3590 - val_accuracy: 0.4909\n",
      "Epoch 9/30\n",
      "5/5 [==============================] - 2s 305ms/step - loss: 0.8318 - accuracy: 0.7263 - val_loss: 1.1804 - val_accuracy: 0.5455\n",
      "Epoch 10/30\n",
      "5/5 [==============================] - 2s 305ms/step - loss: 0.6755 - accuracy: 0.7700 - val_loss: 1.1146 - val_accuracy: 0.6000\n",
      "Epoch 11/30\n",
      "5/5 [==============================] - 2s 304ms/step - loss: 0.5933 - accuracy: 0.7788 - val_loss: 1.1441 - val_accuracy: 0.5636\n",
      "Epoch 12/30\n",
      "5/5 [==============================] - 2s 300ms/step - loss: 0.4202 - accuracy: 0.8648 - val_loss: 1.3186 - val_accuracy: 0.5091\n",
      "Epoch 13/30\n",
      "5/5 [==============================] - 2s 304ms/step - loss: 0.5608 - accuracy: 0.7868 - val_loss: 1.1515 - val_accuracy: 0.5818\n",
      "Epoch 14/30\n",
      "5/5 [==============================] - 2s 304ms/step - loss: 0.3837 - accuracy: 0.9122 - val_loss: 1.2020 - val_accuracy: 0.6000\n",
      "Epoch 15/30\n",
      "5/5 [==============================] - 2s 380ms/step - loss: 0.3863 - accuracy: 0.8730 - val_loss: 1.1724 - val_accuracy: 0.6182\n",
      "Epoch 16/30\n",
      "5/5 [==============================] - 2s 306ms/step - loss: 0.2906 - accuracy: 0.9199 - val_loss: 1.3861 - val_accuracy: 0.6182\n",
      "Epoch 17/30\n",
      "5/5 [==============================] - 2s 309ms/step - loss: 0.2649 - accuracy: 0.9096 - val_loss: 1.2481 - val_accuracy: 0.6545\n",
      "Epoch 18/30\n",
      "5/5 [==============================] - 2s 369ms/step - loss: 0.1705 - accuracy: 0.9648 - val_loss: 1.1668 - val_accuracy: 0.6727\n",
      "Epoch 19/30\n",
      "5/5 [==============================] - 2s 330ms/step - loss: 0.1636 - accuracy: 0.9392 - val_loss: 1.2821 - val_accuracy: 0.6545\n",
      "Epoch 20/30\n",
      "5/5 [==============================] - 2s 363ms/step - loss: 0.1519 - accuracy: 0.9491 - val_loss: 1.2475 - val_accuracy: 0.6727\n",
      "Epoch 21/30\n",
      "5/5 [==============================] - 2s 306ms/step - loss: 0.2260 - accuracy: 0.9353 - val_loss: 1.4180 - val_accuracy: 0.6545\n",
      "Epoch 22/30\n",
      "5/5 [==============================] - 2s 313ms/step - loss: 0.1420 - accuracy: 0.9650 - val_loss: 1.5147 - val_accuracy: 0.6727\n",
      "Epoch 23/30\n",
      "5/5 [==============================] - 2s 302ms/step - loss: 0.0607 - accuracy: 1.0000 - val_loss: 1.5478 - val_accuracy: 0.6364\n",
      "Epoch 24/30\n",
      "5/5 [==============================] - 2s 305ms/step - loss: 0.0511 - accuracy: 0.9962 - val_loss: 1.5981 - val_accuracy: 0.6545\n",
      "Epoch 25/30\n",
      "5/5 [==============================] - 2s 306ms/step - loss: 0.0435 - accuracy: 1.0000 - val_loss: 1.8087 - val_accuracy: 0.6545\n",
      "Epoch 26/30\n",
      "5/5 [==============================] - 2s 302ms/step - loss: 0.0363 - accuracy: 0.9944 - val_loss: 1.8435 - val_accuracy: 0.6909\n",
      "Epoch 27/30\n",
      "5/5 [==============================] - 1s 299ms/step - loss: 0.0229 - accuracy: 0.9944 - val_loss: 1.7439 - val_accuracy: 0.7091\n",
      "Epoch 28/30\n",
      "5/5 [==============================] - 2s 358ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 1.6888 - val_accuracy: 0.6909\n",
      "Epoch 29/30\n",
      "5/5 [==============================] - 2s 330ms/step - loss: 0.0458 - accuracy: 0.9828 - val_loss: 1.8132 - val_accuracy: 0.6727\n",
      "Epoch 30/30\n",
      "5/5 [==============================] - 2s 305ms/step - loss: 0.0325 - accuracy: 0.9880 - val_loss: 1.6495 - val_accuracy: 0.7273\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f11490a08d0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_indices, y_train_oh, epochs = 30, batch_size = 32,\n",
    "          shuffle=True, validation_data=(X_test_indices, y_test_oh))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_dictionary = {\"0\": \"\\u2764\\uFE0F\",    # :heart: prints a black instead of red heart depending on the font\n",
    "                    \"1\": \":baseball:\",\n",
    "                    \"2\": \":smile:\",\n",
    "                    \"3\": \":disappointed:\",\n",
    "                    \"4\": \":fork_and_knife:\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = [\"let's go play tennis\", 'hello world!', \"I love meat\", 'that\\'s awesome', 'I adore you!', 'how sad']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "let's go play tennis ⚾\n",
      "hello world! 😄\n",
      "I love meat 🍴\n",
      "that's awesome 😄\n",
      "I adore you! ❤️\n",
      "how sad 😞\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(t)):\n",
    "    x_test = np.array(t[i:i+1])\n",
    "    X_test_indices = sentences_to_indices(x_test, word_to_index, maxLen)\n",
    "    print(x_test[0] +' '+  label_to_emoji(np.argmax(model.predict(X_test_indices))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DONE :D"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
